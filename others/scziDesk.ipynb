{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/scanpy/api/__init__.py:7: FutureWarning: \n",
      "\n",
      "In a future version of Scanpy, `scanpy.api` will be removed.\n",
      "Simply use `import scanpy as sc` and `import scanpy.external as sce` instead.\n",
      "\n",
      "  FutureWarning,\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import matplotlib.pyplot as plt\n",
    "from scziDesk_preprocess import *\n",
    "from scziDesk_network import *\n",
    "from scziDesk_utils import *\n",
    "import argparse\n",
    "import h5py\n",
    "import time\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, silhouette_score, calinski_harabasz_score\n",
    "from collections import Counter\n",
    "import glob2\n",
    "plt.ion()\n",
    "plt.show()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = [1111, 2222, 3333, 4444, 5555, 6666, 7777, 8888, 9999, 10000]\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"train\", formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "# parser.add_argument(\"--dataname\", default = \"Quake_10x_Bladder\", type = str)\n",
    "parser.add_argument(\"--dataname\", default = \"data_-1.5c15\", type = str)\n",
    "\n",
    "parser.add_argument(\"--distribution\", default = \"ZINB\")\n",
    "parser.add_argument(\"--self_training\", default = True)\n",
    "parser.add_argument(\"--dims\", default = [499, 256, 64, 32])\n",
    "parser.add_argument(\"--highly_genes\", default = 500)\n",
    "parser.add_argument(\"--alpha\", default = 0.001, type = float)\n",
    "parser.add_argument(\"--gamma\", default = 0.001, type = float)\n",
    "parser.add_argument(\"--learning_rate\", default = 0.0001, type = float)\n",
    "parser.add_argument(\"--random_seed\", default = random_seed)\n",
    "parser.add_argument(\"--batch_size\", default = 256, type = int)\n",
    "parser.add_argument(\"--update_epoch\", default = 10, type = int)\n",
    "parser.add_argument(\"--pretrain_epoch\", default = 1000, type = int)\n",
    "parser.add_argument(\"--funetrain_epoch\", default = 2000, type = int)\n",
    "parser.add_argument(\"--t_alpha\", default = 1.0)\n",
    "parser.add_argument(\"--noise_sd\", default = 1.5)\n",
    "parser.add_argument(\"--error\", default = 0.001, type = float)\n",
    "parser.add_argument(\"--gpu_option\", default = \"0\")\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quake_Smart-seq2_Trachea', 'Quake_Smart-seq2_Diaphragm', 'Quake_10x_Spleen', 'Young', 'mouse_ES_cell', 'Adam', 'Quake_10x_Bladder', 'Quake_Smart-seq2_Lung', 'Quake_10x_Limb_Muscle', 'worm_neuron_cell', 'mouse_bladder_cell', 'Romanov', 'Quake_Smart-seq2_Limb_Muscle', 'Muraro', '10X_PBMC']\n",
      ">>>>dataset Quake_Smart-seq2_Trachea\n",
      "(1350, 23341) (1350, 23341)\n",
      "(1350, 500) (1350, 500)\n",
      "WARNING:tensorflow:From /workspace/notebooks/deep_clustering/contrastive-sc/others/scziDesk_network.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/notebooks/deep_clustering/contrastive-sc/others/scziDesk_network.py:29: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /workspace/notebooks/deep_clustering/contrastive-sc/others/scziDesk_loss.py:32: The name tf.lgamma is deprecated. Please use tf.math.lgamma instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/notebooks/deep_clustering/contrastive-sc/others/scziDesk_loss.py:33: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/notebooks/deep_clustering/contrastive-sc/others/scziDesk_loss.py:12: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/notebooks/deep_clustering/contrastive-sc/others/scziDesk_loss.py:12: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /workspace/notebooks/deep_clustering/contrastive-sc/others/scziDesk_network.py:77: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "begin the pretraining\n",
      "WARNING:tensorflow:From /workspace/notebooks/deep_clustering/contrastive-sc/others/scziDesk_network.py:83: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/notebooks/deep_clustering/contrastive-sc/others/scziDesk_network.py:83: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/notebooks/deep_clustering/contrastive-sc/others/scziDesk_network.py:86: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/notebooks/deep_clustering/contrastive-sc/others/scziDesk_network.py:89: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /workspace/notebooks/deep_clustering/contrastive-sc/others/scziDesk_network.py:126: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "begin the funetraining\n",
      "ARI 0.82762, NMI 0.74362\n",
      "0 ARI 0.82762, NMI 0.74362\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.84394, NMI 0.73564\n",
      "0 ARI 0.84394, NMI 0.73564\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.80593, NMI 0.71881\n",
      "0 ARI 0.80593, NMI 0.71881\n",
      ">>>>dataset Quake_Smart-seq2_Diaphragm\n",
      "(870, 23341) (870, 23341)\n",
      "(870, 499) (870, 499)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.96107, NMI 0.93895\n",
      "0 ARI 0.96107, NMI 0.93895\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.95654, NMI 0.93237\n",
      "0 ARI 0.95654, NMI 0.93237\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.9614, NMI 0.93437\n",
      "0 ARI 0.9614, NMI 0.93437\n",
      ">>>>dataset Quake_10x_Spleen\n",
      "(9552, 23341) (9552, 23341)\n",
      "(9552, 500) (9552, 500)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.92289, NMI 0.83523\n",
      "0 ARI 0.92322, NMI 0.83612\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.91324, NMI 0.84064\n",
      "0 ARI 0.91287, NMI 0.8404\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.46743, NMI 0.66087\n",
      "0 ARI 0.46794, NMI 0.661\n",
      "10 ARI 0.91552, NMI 0.85199\n",
      "20 ARI 0.92006, NMI 0.85548\n",
      "30 ARI 0.92321, NMI 0.85859\n",
      "40 ARI 0.92608, NMI 0.8615\n",
      ">>>>dataset Young\n",
      "(5685, 33658) (5685, 33658)\n",
      "(5685, 500) (5685, 500)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.59011, NMI 0.68964\n",
      "0 ARI 0.59296, NMI 0.69173\n",
      "10 ARI 0.61216, NMI 0.70946\n",
      "20 ARI 0.63098, NMI 0.72135\n",
      "30 ARI 0.63854, NMI 0.73028\n",
      "40 ARI 0.64935, NMI 0.73985\n",
      "50 ARI 0.66655, NMI 0.75209\n",
      "60 ARI 0.67506, NMI 0.75994\n",
      "70 ARI 0.68007, NMI 0.76626\n",
      "80 ARI 0.6849, NMI 0.77145\n",
      "90 ARI 0.68403, NMI 0.77121\n",
      "100 ARI 0.68715, NMI 0.77354\n",
      "110 ARI 0.68737, NMI 0.77331\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.67636, NMI 0.77348\n",
      "0 ARI 0.67811, NMI 0.77492\n",
      "10 ARI 0.69198, NMI 0.7817\n",
      "20 ARI 0.70874, NMI 0.78844\n",
      "30 ARI 0.71588, NMI 0.79137\n",
      "40 ARI 0.72413, NMI 0.79661\n",
      "50 ARI 0.73411, NMI 0.80088\n",
      "60 ARI 0.73257, NMI 0.80007\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.6216, NMI 0.74437\n",
      "0 ARI 0.61952, NMI 0.74361\n",
      "10 ARI 0.63234, NMI 0.75397\n",
      "20 ARI 0.64544, NMI 0.76074\n",
      "30 ARI 0.65255, NMI 0.76513\n",
      "40 ARI 0.65428, NMI 0.76578\n",
      "50 ARI 0.6562, NMI 0.76657\n",
      "60 ARI 0.65808, NMI 0.76739\n",
      "70 ARI 0.66008, NMI 0.76869\n",
      "80 ARI 0.66127, NMI 0.76969\n",
      "90 ARI 0.66363, NMI 0.77107\n",
      "100 ARI 0.66479, NMI 0.7716\n",
      "110 ARI 0.66632, NMI 0.77239\n",
      "120 ARI 0.6664, NMI 0.7723\n",
      "130 ARI 0.66776, NMI 0.77344\n",
      "140 ARI 0.66796, NMI 0.77309\n",
      "150 ARI 0.669, NMI 0.77386\n",
      "160 ARI 0.66952, NMI 0.77429\n",
      "170 ARI 0.67014, NMI 0.77467\n",
      "180 ARI 0.66997, NMI 0.77485\n",
      ">>>>dataset mouse_ES_cell\n",
      "(2717, 24175) (2717, 24175)\n",
      "(2717, 500) (2717, 500)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.79327, NMI 0.76967\n",
      "0 ARI 0.79408, NMI 0.77008\n",
      "10 ARI 0.79477, NMI 0.77349\n",
      "20 ARI 0.79592, NMI 0.7747\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.78887, NMI 0.76943\n",
      "0 ARI 0.78615, NMI 0.76973\n",
      "10 ARI 0.79273, NMI 0.77335\n",
      "20 ARI 0.79517, NMI 0.77568\n",
      "30 ARI 0.79517, NMI 0.77568\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.81193, NMI 0.79711\n",
      "0 ARI 0.81031, NMI 0.79476\n",
      "10 ARI 0.81026, NMI 0.79181\n",
      "20 ARI 0.81026, NMI 0.79181\n",
      ">>>>dataset Adam\n",
      "(3660, 23797) (3660, 23797)\n",
      "(3660, 499) (3660, 499)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.84077, NMI 0.83572\n",
      "0 ARI 0.8444, NMI 0.83806\n",
      "10 ARI 0.8519, NMI 0.84509\n",
      "20 ARI 0.85764, NMI 0.84902\n",
      "30 ARI 0.86472, NMI 0.85371\n",
      "40 ARI 0.86536, NMI 0.85382\n",
      "50 ARI 0.86587, NMI 0.85422\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.8361, NMI 0.8464\n",
      "0 ARI 0.83278, NMI 0.84267\n",
      "10 ARI 0.85623, NMI 0.85678\n",
      "20 ARI 0.85764, NMI 0.85836\n",
      "30 ARI 0.86568, NMI 0.86378\n",
      "40 ARI 0.86632, NMI 0.86452\n",
      "50 ARI 0.87224, NMI 0.86831\n",
      "60 ARI 0.87026, NMI 0.86707\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.82812, NMI 0.83637\n",
      "0 ARI 0.82197, NMI 0.83164\n",
      "10 ARI 0.83799, NMI 0.83855\n",
      "20 ARI 0.84388, NMI 0.84318\n",
      "30 ARI 0.84963, NMI 0.84756\n",
      "40 ARI 0.85158, NMI 0.84861\n",
      "50 ARI 0.85355, NMI 0.84998\n",
      ">>>>dataset Quake_10x_Bladder\n",
      "(2500, 23341) (2500, 23341)\n",
      "(2500, 499) (2500, 499)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.98683, NMI 0.97206\n",
      "0 ARI 0.98683, NMI 0.97206\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.98309, NMI 0.96614\n",
      "0 ARI 0.98309, NMI 0.96614\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.97855, NMI 0.9581\n",
      "0 ARI 0.97855, NMI 0.9581\n",
      ">>>>dataset Quake_Smart-seq2_Lung\n",
      "(1676, 23341) (1676, 23341)\n",
      "(1676, 500) (1676, 500)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.74814, NMI 0.82413\n",
      "0 ARI 0.74814, NMI 0.82413\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.76286, NMI 0.8342\n",
      "0 ARI 0.76286, NMI 0.8342\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.75162, NMI 0.81174\n",
      "0 ARI 0.75162, NMI 0.81174\n",
      ">>>>dataset Quake_10x_Limb_Muscle\n",
      "(3909, 23341) (3909, 23341)\n",
      "(3909, 500) (3909, 500)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.97105, NMI 0.94175\n",
      "0 ARI 0.972, NMI 0.94291\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.97194, NMI 0.94853\n",
      "0 ARI 0.97194, NMI 0.94853\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.93833, NMI 0.9067\n",
      "0 ARI 0.93879, NMI 0.90743\n",
      ">>>>dataset worm_neuron_cell\n",
      "(4186, 13488) (4186, 13488)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4186, 499) (4186, 499)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.23573, NMI 0.39892\n",
      "0 ARI 0.23577, NMI 0.39766\n",
      "10 ARI 0.16317, NMI 0.38028\n",
      "20 ARI 0.1062, NMI 0.31739\n",
      "30 ARI 0.08097, NMI 0.27711\n",
      "40 ARI 0.07816, NMI 0.27325\n",
      "50 ARI 0.07641, NMI 0.27082\n",
      "60 ARI 0.07487, NMI 0.26859\n",
      "70 ARI 0.07392, NMI 0.26712\n",
      "80 ARI 0.07326, NMI 0.2664\n",
      "90 ARI 0.07259, NMI 0.26525\n",
      "100 ARI 0.07251, NMI 0.26488\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.18423, NMI 0.35369\n",
      "0 ARI 0.18441, NMI 0.35388\n",
      "10 ARI 0.08361, NMI 0.28927\n",
      "20 ARI 0.05511, NMI 0.21838\n",
      "30 ARI 0.05018, NMI 0.20995\n",
      "40 ARI 0.04466, NMI 0.20299\n",
      "50 ARI 0.04334, NMI 0.20237\n",
      "60 ARI 0.04369, NMI 0.20201\n",
      "70 ARI 0.04366, NMI 0.20187\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.23702, NMI 0.40126\n",
      "0 ARI 0.23767, NMI 0.40234\n",
      "10 ARI 0.13182, NMI 0.3471\n",
      "20 ARI 0.0851, NMI 0.28654\n",
      "30 ARI 0.08049, NMI 0.28171\n",
      "40 ARI 0.0776, NMI 0.27871\n",
      "50 ARI 0.07703, NMI 0.27828\n",
      "60 ARI 0.07673, NMI 0.278\n",
      "70 ARI 0.07662, NMI 0.27793\n",
      "80 ARI 0.07602, NMI 0.27689\n",
      "90 ARI 0.07505, NMI 0.27536\n",
      "100 ARI 0.0745, NMI 0.27482\n",
      ">>>>dataset mouse_bladder_cell\n",
      "(2746, 20670) (2746, 20670)\n",
      "(2746, 499) (2746, 499)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.43659, NMI 0.64716\n",
      "0 ARI 0.43661, NMI 0.64724\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.44207, NMI 0.657\n",
      "0 ARI 0.44232, NMI 0.65706\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.45134, NMI 0.65228\n",
      "0 ARI 0.45163, NMI 0.65246\n",
      ">>>>dataset Romanov\n",
      "(2881, 21143) (2881, 21143)\n",
      "(2881, 500) (2881, 500)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.63612, NMI 0.66494\n",
      "0 ARI 0.63594, NMI 0.66414\n",
      "10 ARI 0.64924, NMI 0.67488\n",
      "20 ARI 0.65308, NMI 0.67624\n",
      "30 ARI 0.65493, NMI 0.67732\n",
      "40 ARI 0.65934, NMI 0.67982\n",
      "50 ARI 0.65971, NMI 0.67991\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.73163, NMI 0.71033\n",
      "0 ARI 0.73913, NMI 0.7155\n",
      "10 ARI 0.74865, NMI 0.72187\n",
      "20 ARI 0.75824, NMI 0.72905\n",
      "30 ARI 0.75932, NMI 0.72976\n",
      "40 ARI 0.76037, NMI 0.73001\n",
      "50 ARI 0.76191, NMI 0.73131\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.72555, NMI 0.70825\n",
      "0 ARI 0.72696, NMI 0.70771\n",
      "10 ARI 0.73058, NMI 0.71789\n",
      "20 ARI 0.73669, NMI 0.72158\n",
      "30 ARI 0.73357, NMI 0.72015\n",
      "40 ARI 0.7356, NMI 0.72064\n",
      "50 ARI 0.73891, NMI 0.7244\n",
      "60 ARI 0.74095, NMI 0.7249\n",
      "70 ARI 0.74195, NMI 0.72576\n",
      ">>>>dataset Quake_Smart-seq2_Limb_Muscle\n",
      "(1090, 23341) (1090, 23341)\n",
      "(1090, 500) (1090, 500)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.97231, NMI 0.9493\n",
      "0 ARI 0.97231, NMI 0.9493\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.97886, NMI 0.96309\n",
      "0 ARI 0.97886, NMI 0.96309\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.97045, NMI 0.94661\n",
      "0 ARI 0.97045, NMI 0.94661\n",
      ">>>>dataset Muraro\n",
      "(2122, 19046) (2122, 19046)\n",
      "(2122, 500) (2122, 500)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.6511, NMI 0.75573\n",
      "0 ARI 0.6511, NMI 0.75573\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.86674, NMI 0.81929\n",
      "0 ARI 0.86375, NMI 0.81764\n",
      "10 ARI 0.87758, NMI 0.82837\n",
      "20 ARI 0.87758, NMI 0.82837\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.65032, NMI 0.75558\n",
      "0 ARI 0.65049, NMI 0.7556\n",
      ">>>>dataset 10X_PBMC\n",
      "(4271, 16653) (4271, 16653)\n",
      "(4271, 499) (4271, 499)\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.48458, NMI 0.66199\n",
      "0 ARI 0.48477, NMI 0.66206\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.61549, NMI 0.71626\n",
      "0 ARI 0.61347, NMI 0.71594\n",
      "10 ARI 0.55222, NMI 0.71056\n",
      "20 ARI 0.61025, NMI 0.7247\n",
      "30 ARI 0.61312, NMI 0.72535\n",
      "40 ARI 0.61454, NMI 0.72682\n",
      "50 ARI 0.61441, NMI 0.72699\n",
      "60 ARI 0.6158, NMI 0.7281\n",
      "70 ARI 0.6171, NMI 0.72849\n",
      "80 ARI 0.61875, NMI 0.72984\n",
      "90 ARI 0.61875, NMI 0.72984\n",
      "begin the pretraining\n",
      "begin the funetraining\n",
      "ARI 0.66697, NMI 0.73201\n",
      "0 ARI 0.6673, NMI 0.7323\n"
     ]
    }
   ],
   "source": [
    "for category in [ \"real_data\",# \"balanced_data\", \"imbalanced_data\",\n",
    "                ]:\n",
    "\n",
    "    path= \"..\"\n",
    "    if category in [\"balanced_data\", \"imbalanced_data\"]:\n",
    "        files = glob2.glob(f'{path}/R/simulated_data/{category}/*.h5')\n",
    "        files = [f[len(f\"{path}/R/simulated_data/{category}/\"):-3] for f in files]\n",
    "    else:\n",
    "        files = glob2.glob(f'{path}/real_data/*.h5')\n",
    "        files = [f[len(f\"{path}/real_data/\"):-3] for f in files]\n",
    "    print(files)\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(columns = [\"dataset\", \"ARI\", \"NMI\", \"sil\", \"run\", \"time\", \"pred\", \"cal\", \"features\"])\n",
    "    for dataset in files:\n",
    "        if category in [\"balanced_data\", \"imbalanced_data\"]:\n",
    "            data_mat = h5py.File(f\"{path}/R/simulated_data/{category}/{dataset}.h5\",\"r\")\n",
    "        else:\n",
    "            data_mat = h5py.File(f\"{path}/real_data/{dataset}.h5\",\"r\")\n",
    "\n",
    "        Y = np.array(data_mat['Y'])\n",
    "        X = np.array(data_mat['X'])\n",
    "        print(f\">>>>dataset {dataset}\")\n",
    "        if X.shape[0] > 10000:\n",
    "            continue\n",
    "\n",
    "        X = np.ceil(X).astype(np.int)\n",
    "        count_X = X\n",
    "        print(X.shape, count_X.shape)\n",
    "        orig_X = X.copy()\n",
    "        adata = sc.AnnData(X)\n",
    "        adata.obs['Group'] = Y\n",
    "        adata = normalize(adata,\n",
    "                          copy=True,\n",
    "                          highly_genes=args.highly_genes,\n",
    "                          size_factors=True,\n",
    "                          normalize_input=True,\n",
    "                          logtrans_input=True)\n",
    "        X = adata.X.astype(np.float32)\n",
    "        Y = np.array(adata.obs[\"Group\"])\n",
    "\n",
    "        high_variable = np.array(adata.var.highly_variable.index, dtype=np.int)\n",
    "        count_X = count_X[:, high_variable]\n",
    "        size_factor = np.array(adata.obs.size_factors).reshape(-1,\n",
    "                                                               1).astype(np.float32)\n",
    "        cluster_number = int(max(Y) - min(Y) + 1)\n",
    "        args.dims[0]=X.shape[1]\n",
    "        print(X.shape, count_X.shape)\n",
    "\n",
    "        for run in range(3):\n",
    "            start = time.time()\n",
    "            seed = run\n",
    "            np.random.seed(seed)\n",
    "            tf.reset_default_graph()\n",
    "            chencluster = autoencoder(args.dataname, args.distribution,\n",
    "                                      args.self_training, args.dims, cluster_number,\n",
    "                                      args.t_alpha, args.alpha, args.gamma,\n",
    "                                      args.learning_rate, args.noise_sd)\n",
    "\n",
    "            chencluster.pretrain(X, count_X, size_factor, args.batch_size,\n",
    "                                 args.pretrain_epoch, args.gpu_option)\n",
    "\n",
    "            chencluster.funetrain(X, count_X, size_factor, args.batch_size,\n",
    "                                  args.funetrain_epoch, args.update_epoch, args.error, Y)\n",
    "\n",
    "            kmeans_ARI = np.around(adjusted_rand_score(Y, chencluster.kmeans_pred), 5)\n",
    "            kmeans_NMI = np.around(\n",
    "                normalized_mutual_info_score(Y, chencluster.kmeans_pred), 5)\n",
    "\n",
    "            elapsed = time.time() - start\n",
    "            ARI = adjusted_rand_score(Y, chencluster.Y_pred)\n",
    "            NMI = np.around(normalized_mutual_info_score(Y, chencluster.Y_pred), 5)\n",
    "            ss = silhouette_score(chencluster.latent_repre,chencluster.Y_pred)\n",
    "            cal = calinski_harabasz_score(chencluster.latent_repre,chencluster.Y_pred)\n",
    "\n",
    "            df.loc[df.shape[0]] = [dataset, ARI, NMI, ss, run, elapsed, chencluster.Y_pred, cal, \n",
    "                                   chencluster.latent_repre]\n",
    "            df.to_pickle(f\"../output/pickle_results/{category}/{category}_sczi.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARI       0.752219\n",
       "NMI       0.780598\n",
       "sil       0.256274\n",
       "run       1.000000\n",
       "time    152.106023\n",
       "cal     596.273096\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"dataset\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
