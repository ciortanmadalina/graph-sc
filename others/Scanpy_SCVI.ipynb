{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.scvi-tools.org/en/stable/user_guide/notebooks/api_overview.html  \n",
    "https://github.com/YosefLab/scvi-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install leidenalg\n",
    "# !pip install scanpy==1.7.0\n",
    "# !pip install scvi-tools\n",
    "#!pip install --user scikit-misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, calinski_harabasz_score, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy as sp\n",
    "# import scanpy as sc # scanpy version 1.5\n",
    "import scanpy.api as sc # scanpy version 1.7\n",
    "from collections import Counter\n",
    "import time\n",
    "import scvi\n",
    "import pickle\n",
    "import os\n",
    "import glob2\n",
    "plt.ion()\n",
    "plt.show()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for category in [\n",
    "        \"balanced_data\",\n",
    "        \"imbalanced_data\",\n",
    "        \"real_data\",\n",
    "]:\n",
    "\n",
    "    path = \"..\"\n",
    "    if category in [\"balanced_data\", \"imbalanced_data\"]:\n",
    "        files = glob2.glob(f'{path}/R/simulated_data/{category}/*.h5')\n",
    "        files = [\n",
    "            f[len(f\"{path}/R/simulated_data/{category}/\"):-3] for f in files\n",
    "        ]\n",
    "    else:\n",
    "        files = glob2.glob(f'{path}/real_data/*.h5')\n",
    "        files = [f[len(f\"{path}/real_data/\"):-3] for f in files]\n",
    "    print(files)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        columns=[\"dataset\", \"ARI\", \"NMI\", \"sil\", \"run\", \"time\", \"pred\", \"cal\"])\n",
    "    for dataset in files:\n",
    "        if category in [\"balanced_data\", \"imbalanced_data\"]:\n",
    "            data_mat = h5py.File(\n",
    "                f\"{path}/R/simulated_data/{category}/{dataset}.h5\", \"r\")\n",
    "        else:\n",
    "            data_mat = h5py.File(f\"{path}/real_data/{dataset}.h5\", \"r\")\n",
    "\n",
    "        Y = np.array(data_mat['Y'])\n",
    "        X = np.array(data_mat['X'])\n",
    "        print(f\">>>>dataset {dataset}\")\n",
    "\n",
    "        X = np.ceil(X).astype(np.int)\n",
    "        for run in range(3):\n",
    "            start = time.time()\n",
    "            adata = sc.AnnData(X)\n",
    "            adata.obs['Group'] = Y\n",
    "            adata.var_names_make_unique()\n",
    "\n",
    "            adata.layers[\"counts\"] = adata.X.copy()  # preserve counts\n",
    "            sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "            sc.pp.log1p(adata)\n",
    "            adata.raw = adata  # freeze the state in `.raw`\n",
    "            #             sc.pp.highly_variable_genes( # old version of scanpy\n",
    "            #                 adata,\n",
    "            #                 n_top_genes=2000,\n",
    "            #                 subset=True,\n",
    "            #                 flavor=\"seurat\",\n",
    "            # #                 layer=\"counts\",\n",
    "\n",
    "            #             )\n",
    "            sc.pp.highly_variable_genes( # scanpy 1.7\n",
    "                adata,\n",
    "                n_top_genes=2000,\n",
    "                subset=True,\n",
    "                flavor=\"seurat_v3\",\n",
    "                layer=\"counts\",\n",
    "            )\n",
    "            scvi.data.setup_anndata(adata, layer=\"counts\")\n",
    "            model = scvi.model.SCVI(adata)\n",
    "            model.train()\n",
    "            latent = model.get_latent_representation()\n",
    "            adata.obsm[\"X_scVI\"] = latent\n",
    "            adata.layers[\"scvi_normalized\"] = model.get_normalized_expression(\n",
    "                library_size=10e4)\n",
    "\n",
    "            sc.pp.neighbors(adata, use_rep=\"X_scVI\")\n",
    "            sc.tl.umap(adata, min_dist=0.2)\n",
    "            sc.tl.leiden(adata, key_added=\"leiden_scVI\")\n",
    "\n",
    "            pred = adata.obs['leiden_scVI'].to_list()\n",
    "            pred = [int(x) for x in pred]\n",
    "\n",
    "            elapsed = time.time() - start\n",
    "            ARI = adjusted_rand_score(Y, pred)\n",
    "            NMI = np.around(normalized_mutual_info_score(Y, pred), 5)\n",
    "            ss = silhouette_score(adata.obsm[\"X_umap\"], pred)\n",
    "            cal = calinski_harabasz_score(adata.obsm[\"X_umap\"], pred)\n",
    "\n",
    "            df.loc[df.shape[0]] = [\n",
    "                dataset, ARI, NMI, ss, run, elapsed, pred, cal\n",
    "            ]\n",
    "            df.to_pickle(\n",
    "                f\"../output/pickle_results/{category}/{category}_scvi.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
