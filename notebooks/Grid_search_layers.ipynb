{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dgl-cu101==0.5.3\n",
    "# !pip install scikit_learn==0.22.2.post1\n",
    "# !pip install xlrd==1.2.0\n",
    "# !pip install leidenalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "import dgl.function as fn\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from dgl.data import register_data_args, load_data\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits as BCELoss\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import h5py\n",
    "import random\n",
    "import train\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import glob2\n",
    "import scanpy.api as sc\n",
    "import models\n",
    "import seaborn as sns\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = train.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"real_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 128 \n",
    "pca_size = 50\n",
    "path = \"../\"\n",
    "files = glob2.glob(f'{path}real_data/*.h5')\n",
    "files = [f[len(f\"'{path}real_data\"):-3] for f in files]\n",
    "print(files)\n",
    "nb_genes =2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.DataFrame()\n",
    "results = pd.read_pickle(\n",
    "    f\"../output/pickle_results/{category}/{category}_gae_layers.pkl\")\n",
    "model_name = \"GraphConv\"\n",
    "normalize_weights = \"log_per_cell\"\n",
    "node_features = \"scale\"\n",
    "same_edge_values = False\n",
    "edge_norm = True\n",
    "hidden_relu = False\n",
    "hidden_bn = False\n",
    "n_layers = 1\n",
    "hidden_dim = 200\n",
    "hidden = [300]\n",
    "nb_genes = 3000\n",
    "activation = F.relu\n",
    "for dataset in files:\n",
    "    print(f\">> {dataset}\")\n",
    "\n",
    "    data_mat = h5py.File(f\"{path}/real_data/{dataset}.h5\", \"r\")\n",
    "\n",
    "    Y = np.array(data_mat['Y'])\n",
    "    X = np.array(data_mat['X'])\n",
    "\n",
    "    genes_idx, cells_idx = train.filter_data(X, highly_genes=nb_genes)\n",
    "    X = X[cells_idx][:, genes_idx]\n",
    "    Y = Y[cells_idx]\n",
    "    n_clusters = len(np.unique(Y))\n",
    "    for hidden_dim in [200, 100, 300, 150]:\n",
    "        for hidden in [[300][50, 50], [50][300], [400], [200, 200], [300, 300],\n",
    "                       [400, 400][200], [100], None, [100, 100]]:\n",
    "            t0 = time.time()\n",
    "            graph = train.make_graph(\n",
    "                X,\n",
    "                Y,\n",
    "                dense_dim=pca_size,\n",
    "                node_features=node_features,\n",
    "                normalize_weights=normalize_weights,\n",
    "            )\n",
    "\n",
    "            labels = graph.ndata[\"label\"]\n",
    "            train_ids = np.where(labels != -1)[0]\n",
    "\n",
    "            sampler = dgl.dataloading.MultiLayerFullNeighborSampler(n_layers)\n",
    "\n",
    "            dataloader = dgl.dataloading.NodeDataLoader(\n",
    "                graph,\n",
    "                train_ids,\n",
    "                sampler,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                drop_last=False,\n",
    "                num_workers=1,\n",
    "            )\n",
    "            print(\n",
    "                f\"INPUT: {model_name}  {hidden_dim}, {hidden}, {same_edge_values}, {edge_norm}\"\n",
    "            )\n",
    "            t1 = time.time()\n",
    "\n",
    "            for run in range(3):\n",
    "                t_start = time.time()\n",
    "                torch.manual_seed(run)\n",
    "                torch.cuda.manual_seed_all(run)\n",
    "                np.random.seed(run)\n",
    "                random.seed(run)\n",
    "\n",
    "                model = models.GCNAE(\n",
    "                    in_feats=pca_size,\n",
    "                    n_hidden=hidden_dim,\n",
    "                    n_layers=n_layers,\n",
    "                    activation=activation,\n",
    "                    dropout=0.1,\n",
    "                    hidden=hidden,\n",
    "                    hidden_relu=hidden_relu,\n",
    "                    hidden_bn=hidden_bn,\n",
    "                ).to(device)\n",
    "                if run == 0:\n",
    "                    print(f\">\", model)\n",
    "\n",
    "                optim = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "                scores = train.train(model,\n",
    "                                     optim,\n",
    "                                     epochs,\n",
    "                                     dataloader,\n",
    "                                     n_clusters,\n",
    "                                     plot=False,\n",
    "                                     cluster=[\"KMeans\", \"Leiden\"])\n",
    "                scores[\"dataset\"] = dataset\n",
    "                scores[\"run\"] = run\n",
    "                scores[\"nb_genes\"] = nb_genes\n",
    "                scores[\"hidden\"] = str(hidden)\n",
    "                scores[\"hidden_dim\"] = str(hidden_dim)\n",
    "\n",
    "                results = results.append(scores, ignore_index=True)\n",
    "\n",
    "                results.to_pickle(\n",
    "                    f\"../output/pickle_results/{category}/{category}_gae_layers.pkl\"\n",
    "                )\n",
    "                print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_pickle(\n",
    "    f\"../output/pickle_results/{category}/{category}_gae_layers.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"combined\"]=results[\"nb_genes\"].astype(str)+ results[\"hidden\"] +results[\"hidden_dim\"].astype(str)\n",
    "\n",
    "results = results[(results[\"combined\"] != '3000.0[300]200')]\n",
    "results.drop(\"combined\", axis=1, inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
