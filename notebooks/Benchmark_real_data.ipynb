{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "import numpy as np\n",
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import h5py\n",
    "import random\n",
    "import glob2\n",
    "import seaborn as sns\n",
    "\n",
    "import train\n",
    "import models\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = train.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"real_data\"\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128 \n",
    "pca_size = 50\n",
    "path = \"../\"\n",
    "files = glob2.glob(f'{path}real_data/*.h5')\n",
    "files = [f[len(f\"'{path}real_data\"):-3] for f in files]\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "model_name = \"GraphConv\"\n",
    "normalize_weights = \"log_per_cell\"\n",
    "node_features = \"scale\"\n",
    "same_edge_values = False\n",
    "edge_norm = True\n",
    "hidden_relu = False\n",
    "hidden_bn = False\n",
    "n_layers = 1\n",
    "hidden_dim = 200\n",
    "hidden = [300]\n",
    "nb_genes = 3000\n",
    "activation = F.relu\n",
    "for dataset in files:\n",
    "    print(f\">> {dataset}\")\n",
    "\n",
    "    data_mat = h5py.File(f\"{path}/real_data/{dataset}.h5\", \"r\")\n",
    "\n",
    "    Y = np.array(data_mat['Y'])\n",
    "    X = np.array(data_mat['X'])\n",
    "    n_clusters = len(np.unique(Y))\n",
    "\n",
    "    genes_idx, cells_idx = train.filter_data(X, highly_genes=nb_genes)\n",
    "    X = X[cells_idx][:, genes_idx]\n",
    "    Y = Y[cells_idx]\n",
    "\n",
    "    t0 = time.time()\n",
    "    graph = train.make_graph(\n",
    "        X,\n",
    "        Y,\n",
    "        dense_dim=pca_size,\n",
    "        node_features=node_features,\n",
    "        normalize_weights=normalize_weights,\n",
    "    )\n",
    "\n",
    "    labels = graph.ndata[\"label\"]\n",
    "    train_ids = np.where(labels != -1)[0]\n",
    "\n",
    "    sampler = dgl.dataloading.MultiLayerFullNeighborSampler(n_layers)\n",
    "\n",
    "    dataloader = dgl.dataloading.NodeDataLoader(\n",
    "        graph,\n",
    "        train_ids,\n",
    "        sampler,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=1,\n",
    "    )\n",
    "    print(\n",
    "        f\"INPUT: {model_name}  {hidden_dim}, {hidden}, {same_edge_values}, {edge_norm}\"\n",
    "    )\n",
    "    t1 = time.time()\n",
    "\n",
    "    for run in range(3):\n",
    "        t_start = time.time()\n",
    "        torch.manual_seed(run)\n",
    "        torch.cuda.manual_seed_all(run)\n",
    "        np.random.seed(run)\n",
    "        random.seed(run)\n",
    "\n",
    "        model = models.GCNAE(\n",
    "            in_feats=pca_size,\n",
    "            n_hidden=hidden_dim,\n",
    "            n_layers=n_layers,\n",
    "            activation=activation,\n",
    "            dropout=0.1,\n",
    "            hidden=hidden,\n",
    "            hidden_relu=hidden_relu,\n",
    "            hidden_bn=hidden_bn,\n",
    "        ).to(device)\n",
    "        if run == 0:\n",
    "            print(f\">\", model)\n",
    "\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "        scores = train.train(model,\n",
    "                             optim,\n",
    "                             epochs,\n",
    "                             dataloader,\n",
    "                             n_clusters,\n",
    "                             plot=False,\n",
    "                             cluster=[\"KMeans\", \"Leiden\"])\n",
    "        scores[\"dataset\"] = dataset\n",
    "        scores[\"run\"] = run\n",
    "        scores[\"nb_genes\"] = nb_genes\n",
    "        scores[\"hidden\"] = str(hidden)\n",
    "        scores[\"hidden_dim\"] = str(hidden_dim)\n",
    "        scores[\"tot_kmeans_time\"] = (t1 - t0) + (\n",
    "            scores['ae_end'] - t_start) + scores['kmeans_time']\n",
    "        scores[\"tot_leiden_time\"] = (t1 - t0) + (\n",
    "            scores['ae_end'] - t_start) + scores['leiden_time']\n",
    "        scores[\"time_graph\"] = t1 - t0\n",
    "        scores[\"time_training\"] = (scores['ae_end'] - t_start)\n",
    "\n",
    "        results = results.append(scores, ignore_index=True)\n",
    "\n",
    "#         results.to_pickle(\n",
    "#             f\"../output/pickle_results/{category}/{category}_gae.pkl\")\n",
    "#         print(\"Done\")\n",
    "\n",
    "results.mean()  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"real_data\"\n",
    "results = pd.read_pickle(\n",
    "    f\"../output/pickle_results/{category}/{category}_gae.pkl\")\n",
    "\n",
    "results.mean()  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results[[\"dataset\", \"run\" , \"kmeans_ari\", \"leiden_ari\"]]\n",
    "\n",
    "results = results.groupby(\"dataset\")[[ \"kmeans_ari\", \"leiden_ari\"]].mean()\n",
    "\n",
    "results1 = pd.read_pickle(\n",
    "    f\"../output/pickle_results/{category}/{category}_gae_corr.pkl\")\n",
    "# results1.mean()\n",
    "\n",
    "results1 = results1[[\"dataset\", \"run\" , \"kmeans_ari\", \"leiden_ari\"]]\n",
    "\n",
    "results1 = results1.groupby(\"dataset\")[[ \"kmeans_ari\", \"leiden_ari\"]].mean()\n",
    "pd.merge(results, results1, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPU analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = train.get_device(use_cpu = True)\n",
    "print(device)\n",
    "category = \"real_data\"\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 128 \n",
    "pca_size = 50\n",
    "path = \"../\"\n",
    "files = glob2.glob(f'{path}real_data/*.h5')\n",
    "files = [f[len(f\"'{path}real_data\"):-3] for f in files]\n",
    "print(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "model_name = \"GraphConv\"\n",
    "normalize_weights = \"log_per_cell\"\n",
    "node_features = \"scale\"\n",
    "same_edge_values = False\n",
    "edge_norm = True\n",
    "hidden_relu = False\n",
    "hidden_bn = False\n",
    "n_layers = 1\n",
    "hidden_dim = 200\n",
    "hidden = [300]\n",
    "nb_genes = 3000\n",
    "activation = F.relu\n",
    "for dataset in files:\n",
    "    print(f\">> {dataset}\")\n",
    "\n",
    "    data_mat = h5py.File(f\"{path}/real_data/{dataset}.h5\", \"r\")\n",
    "\n",
    "    Y = np.array(data_mat['Y'])\n",
    "    X = np.array(data_mat['X'])\n",
    "    n_clusters = len(np.unique(Y))\n",
    "\n",
    "    genes_idx, cells_idx = train.filter_data(X, highly_genes=nb_genes)\n",
    "    X = X[cells_idx][:, genes_idx]\n",
    "    Y = Y[cells_idx]\n",
    "\n",
    "    t0 = time.time()\n",
    "    graph = train.make_graph(\n",
    "        X,\n",
    "        Y,\n",
    "        dense_dim=pca_size,\n",
    "        node_features=node_features,\n",
    "        normalize_weights=normalize_weights,\n",
    "    )\n",
    "\n",
    "    labels = graph.ndata[\"label\"]\n",
    "    train_ids = np.where(labels != -1)[0]\n",
    "\n",
    "    sampler = dgl.dataloading.MultiLayerFullNeighborSampler(n_layers)\n",
    "\n",
    "    dataloader = dgl.dataloading.NodeDataLoader(\n",
    "        graph,\n",
    "        train_ids,\n",
    "        sampler,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        drop_last=False,\n",
    "        num_workers=1,\n",
    "    )\n",
    "    print(\n",
    "        f\"INPUT: {model_name}  {hidden_dim}, {hidden}, {same_edge_values}, {edge_norm}\"\n",
    "    )\n",
    "    t1 = time.time()\n",
    "\n",
    "    for run in range(3):\n",
    "        t_start = time.time()\n",
    "        torch.manual_seed(run)\n",
    "        torch.cuda.manual_seed_all(run)\n",
    "        np.random.seed(run)\n",
    "        random.seed(run)\n",
    "\n",
    "        model = models.GCNAE(\n",
    "            in_feats=pca_size,\n",
    "            n_hidden=hidden_dim,\n",
    "            n_layers=n_layers,\n",
    "            activation=activation,\n",
    "            dropout=0.1,\n",
    "            hidden=hidden,\n",
    "            hidden_relu=hidden_relu,\n",
    "            hidden_bn=hidden_bn,\n",
    "        ).to(device)\n",
    "        if run == 0:\n",
    "            print(f\">\", model)\n",
    "\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "        scores = train.train(model, optim, epochs, dataloader, n_clusters, plot=False,\n",
    "                            cluster=[\"KMeans\", \"Leiden\"], use_cpu = True)\n",
    "        scores[\"dataset\"] = dataset\n",
    "        scores[\"run\"] = run\n",
    "        scores[\"nb_genes\"] = nb_genes\n",
    "        scores[\"hidden\"] = str(hidden)\n",
    "        scores[\"hidden_dim\"] = str(hidden_dim)\n",
    "        scores[\"tot_kmeans_time\"] = (t1-t0) + (scores['ae_end'] - t_start) + scores['kmeans_time']\n",
    "        scores[\"tot_leiden_time\"] = (t1-t0) + (scores['ae_end'] - t_start) + scores['leiden_time']\n",
    "        scores[\"time_graph\"] = t1-t0\n",
    "        scores[\"time_training\"] = (scores['ae_end'] - t_start)\n",
    "\n",
    "        results = results.append(scores, ignore_index = True)\n",
    "\n",
    "        results.to_pickle(\n",
    "            f\"../output/pickle_results/{category}/{category}_gae_cpu.pkl\")\n",
    "        print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
