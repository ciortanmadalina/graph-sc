{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "import numpy as np\n",
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import h5py\n",
    "import random\n",
    "import glob2\n",
    "import seaborn as sns\n",
    "\n",
    "import train\n",
    "import models\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = train.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"real_data\"\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "pca_size = 50\n",
    "path = \"../\"\n",
    "files = glob2.glob(f'{path}real_data/*.h5')\n",
    "files = [f[len(f\"'{path}real_data\"):-3] for f in files]\n",
    "print(files)\n",
    "files = [\n",
    "    'Quake_10x_Spleen',\n",
    "    'Quake_Smart-seq2_Trachea',\n",
    "    'Muraro',\n",
    "    \n",
    "    \n",
    "    'worm_neuron_cell',\n",
    "    'mouse_ES_cell',\n",
    "    \n",
    "    'Young',\n",
    "    'Adam',\n",
    "    'Quake_10x_Bladder',\n",
    "    'Quake_Smart-seq2_Lung',\n",
    "    'Quake_10x_Limb_Muscle',\n",
    "    \n",
    "    'mouse_bladder_cell',\n",
    "    'Romanov',\n",
    "    'Quake_Smart-seq2_Limb_Muscle',\n",
    "    \n",
    "    '10X_PBMC',\n",
    "    \n",
    "    'Quake_Smart-seq2_Diaphragm',\n",
    "    \n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "model_name = \"GraphConv\"\n",
    "normalize_weights = \"log_per_cell\"\n",
    "node_features = \"scale\"\n",
    "same_edge_values = False\n",
    "edge_norm = True\n",
    "hidden_relu = False\n",
    "hidden_bn = False\n",
    "n_layers = 2\n",
    "\n",
    "hidden_dim = 200\n",
    "hidden = [300]\n",
    "nb_genes = 3000\n",
    "activation = F.relu\n",
    "for dataset in files:\n",
    "    print(f\">> {dataset}\")\n",
    "\n",
    "    data_mat = h5py.File(f\"{path}/real_data/{dataset}.h5\", \"r\")\n",
    "    if \"gene_names\" not in data_mat.keys():\n",
    "        continue\n",
    "    for factor in [100, 200, 500]: # limit the nb of introduced correlations\n",
    "        w=1\n",
    "        gene_names = data_mat[\"gene_names\"][()]\n",
    "        Y = np.array(data_mat['Y'])\n",
    "        X = np.array(data_mat['X'])\n",
    "        batch_size = 64 if X.shape[0] <5000 else 25\n",
    "        t0 = time.time()\n",
    "        genes_idx, cells_idx = train.filter_data(X, highly_genes=nb_genes)\n",
    "        X = X[cells_idx][:, genes_idx]\n",
    "        Y = Y[cells_idx]\n",
    "        gene_names = gene_names[genes_idx]\n",
    "        max_size = X.shape[0] * X.shape[1]//factor\n",
    "        gene_data = train.tissue_data(\n",
    "            gene_names,\n",
    "            filename=\"../../gene_network/41598_2017_4520_MOESM2_ESM.pkl\",\n",
    "            threshold=0.5,\n",
    "            plot=False,\n",
    "            method='pearson',\n",
    "            max_size = max_size)\n",
    "\n",
    "        gene_data[\"single_layer\"] = False\n",
    "        gene_data[\"weight\"] = w\n",
    "\n",
    "\n",
    "        graph = train.make_graph(\n",
    "            X,\n",
    "            Y,\n",
    "            dense_dim=pca_size,\n",
    "            node_features=node_features,\n",
    "            normalize_weights=normalize_weights,\n",
    "            threshold = 0,\n",
    "            gene_data = gene_data\n",
    "        )\n",
    "\n",
    "        labels = graph.ndata[\"label\"]\n",
    "        train_ids = np.where(labels != -1)[0]\n",
    "\n",
    "        sampler = dgl.dataloading.MultiLayerFullNeighborSampler(n_layers)\n",
    "\n",
    "        dataloader = dgl.dataloading.NodeDataLoader(\n",
    "            graph,\n",
    "            train_ids,# np.arange(len(labels)), #\n",
    "            sampler,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "            num_workers=1,\n",
    "        )\n",
    "        print(\n",
    "            f\"INPUT: {factor}, {w}, {model_name}  {hidden_dim}, {hidden}, {same_edge_values}, {edge_norm}\"\n",
    "        )\n",
    "        t1 = time.time()\n",
    "\n",
    "        for run in range(3):\n",
    "            t_start = time.time()\n",
    "            torch.manual_seed(run)\n",
    "            torch.cuda.manual_seed_all(run)\n",
    "            np.random.seed(run)\n",
    "            random.seed(run)\n",
    "\n",
    "            model = models.GCNAE(\n",
    "                in_feats=pca_size,\n",
    "                n_hidden=hidden_dim,\n",
    "                n_layers=n_layers,\n",
    "                activation=activation,\n",
    "                dropout=0.1,\n",
    "                hidden=hidden,\n",
    "                hidden_relu=hidden_relu,\n",
    "                hidden_bn=hidden_bn,\n",
    "            ).to(device)\n",
    "            if run == 0:\n",
    "                print(f\">\", model)\n",
    "\n",
    "            optim = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "            model = train.train(model, optim, epochs, dataloader, plot=False,\n",
    "                                cluster=[\"KMeans\", \"Leiden\"])\n",
    "\n",
    "            dataloader = dgl.dataloading.NodeDataLoader(\n",
    "                graph,\n",
    "                train_ids,\n",
    "                sampler,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                drop_last=False,\n",
    "                num_workers=1,\n",
    "            )\n",
    "            scores = train.evaluate(model, dataloader, save=True, cluster=[\"KMeans\", \"Leiden\"], use_cpu = False)\n",
    "\n",
    "            print(f'ARI {scores.get(\"kmeans_ari\")}, {scores.get(\"kmeans_sil\")}')\n",
    "\n",
    "\n",
    "            scores[\"dataset\"] = dataset\n",
    "            scores[\"run\"] = run\n",
    "            scores[\"nb_genes\"] = nb_genes\n",
    "            scores[\"hidden\"] = str(hidden)\n",
    "            scores[\"hidden_dim\"] = str(hidden_dim)\n",
    "            scores[\"tot_kmeans_time\"] = (t1-t0) + (scores['ae_end'] - t_start) + scores['kmeans_time']\n",
    "            scores[\"tot_leiden_time\"] = (t1-t0) + (scores['ae_end'] - t_start) + scores['leiden_time']\n",
    "            scores[\"time_graph\"] = t1-t0\n",
    "            scores[\"time_training\"] = (scores['ae_end'] - t_start)\n",
    "            scores[\"factor\"] = factor\n",
    "            scores[\"w\"] = w\n",
    "\n",
    "            results = results.append(scores, ignore_index = True)\n",
    "\n",
    "            results.to_pickle(\n",
    "                f\"../output/pickle_results/{category}/{category}_gae_tissue.pkl\")\n",
    "            print(\"Done\")\n",
    "\n",
    "results.mean()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = \"real_data\"\n",
    "results = pd.read_pickle(\n",
    "                f\"../output/pickle_results/{category}/{category}_gae_tissue.pkl\")\n",
    "results = results[~results[\"dataset\"].isin([\"Muraro\", \"Adam\"])] # Exclude human datasets\n",
    "# results.groupby([\"dataset\", \"factor\"] )[\"kmeans_ari\"].mean().unstack(\"factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = results.groupby([\"dataset\", \"factor\"] )[\"kmeans_ari\"].mean().unstack(\"factor\")\n",
    "v[\"best\"] =v.values.argmax(axis = 1)\n",
    "v = v.reset_index()\n",
    "v[\"sel\"] = v.apply(lambda x: f\"{x['dataset']}_{[100, 200, 500][x['best']]}\", axis = 1)\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"sel\"] = results.apply(lambda x: f\"{x['dataset']}_{int(x['factor'])}\", axis = 1)\n",
    "result1 = results[results[\"sel\"].isin(v[\"sel\"].values)]\n",
    "result1[\"Type\"] = \"with external data\"\n",
    "result1 = result1[[\"dataset\", \"run\" , \"kmeans_ari\", \"Type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get baseline model as results\n",
    "results = pd.read_pickle(\n",
    "    f\"../output/pickle_results/{category}/{category}_gae.pkl\")\n",
    "\n",
    "results = results[results[\"dataset\"].isin(result1.dataset.values)]\n",
    "\n",
    "results = results[[\"dataset\", \"run\" , \"kmeans_ari\", ]]\n",
    "results[\"Type\"] = \"baseline\"\n",
    "# Merge baseline with external data results\n",
    "m = pd.concat([results, result1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = {\n",
    "    '10X_PBMC': '10X PBMC',\n",
    "    '10X_PBMC_select_2100': '10X PBMC (2100)',\n",
    "    'mouse_ES_cell': 'Mouse ES Cell',\n",
    "    'mouse_ES_cell_select_2100': 'Mouse ES Cell (2100)',\n",
    "    'worm_neuron_cell_select_2100': 'Worm Neuron Cell (2100)',\n",
    "    'worm_neuron_cell': 'Worm Neuron Cell',\n",
    "    'mouse_bladder_cell': 'Mouse Bladder Cell',\n",
    "    'mouse_bladder_cell_select_2100': 'Mouse Bladder  Cell (2100)',\n",
    "    'Quake_Smart-seq2_Trachea': 'QS Trachea',\n",
    "    'Quake_Smart-seq2_Diaphragm': 'QS Diaphragm',\n",
    "    'Quake_10x_Spleen': 'Q Spleen',\n",
    "    'Quake_10x_Bladder': 'Q Bladder',\n",
    "    'Quake_Smart-seq2_Lung': 'QS Lung',\n",
    "    'Quake_10x_Limb_Muscle': 'Q Limb Muscle',\n",
    "    'Quake_Smart-seq2_Limb_Muscle': 'QS Limb Muscle',\n",
    "}\n",
    "\n",
    "m[\"dataset_label\"] = m[\"dataset\"].apply(\n",
    "    lambda x: dataset_names.get(x, x))\n",
    "\n",
    "datasets = [\n",
    "    'Quake_Smart-seq2_Trachea',\n",
    "    'Quake_10x_Bladder',\n",
    "    'Quake_10x_Spleen',\n",
    "    'Quake_Smart-seq2_Diaphragm',\n",
    "    'Quake_10x_Limb_Muscle',\n",
    "    'Quake_Smart-seq2_Limb_Muscle',\n",
    "    'Romanov',\n",
    "    'Adam',\n",
    "    'Muraro',\n",
    "    'Young',\n",
    "    'Quake_Smart-seq2_Lung',\n",
    "    '10X_PBMC',\n",
    "    'mouse_ES_cell',\n",
    "    'worm_neuron_cell',\n",
    "    'mouse_bladder_cell',\n",
    "]\n",
    "\n",
    "ordered_datasets = dict(zip(datasets, np.arange(len(datasets))))\n",
    "\n",
    "m[\"ordered_dataset\"] = m[\"dataset\"].apply(lambda x: ordered_datasets[x])\n",
    "\n",
    "res = m.groupby([\"dataset_label\", \"Type\"])[[\"kmeans_ari\", \"ordered_dataset\"]].mean().unstack(\"Type\").round(2)\n",
    "res\n",
    "\n",
    "res.columns = [\"baseline\", \"with external data\", \"a\", \"b\"]\n",
    "\n",
    "res\n",
    "\n",
    "res = res.sort_values(by=[\"a\"]).drop([\"a\", \"b\"], axis = 1)\n",
    "\n",
    "res\n",
    "\n",
    "plt.figure(figsize = (5, 4))\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "sns.heatmap(res, annot=True, cmap=\"coolwarm\", fmt='.3g', ax=ax, cbar=False)\n",
    "plt.ylabel(\"\");\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"../diagrams/external_results.svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
