{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import argparse\n",
    "import numpy as np\n",
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import h5py\n",
    "import random\n",
    "import glob2\n",
    "import seaborn as sns\n",
    "\n",
    "import train\n",
    "import models\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device = train.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model_name = \"GraphConv\"\n",
    "normalize_weights = \"log_per_cell\"\n",
    "node_features = \"scale\"\n",
    "same_edge_values = False\n",
    "edge_norm = True\n",
    "hidden_relu = False\n",
    "hidden_bn = False\n",
    "n_layers = 1\n",
    "pca_size = 50\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "hidden_dim = 200\n",
    "hidden = [300]\n",
    "nb_genes = 3000\n",
    "activation = F.relu\n",
    "for category in [\"real_data\"#\"balanced_data\", \"imbalanced_data\", \n",
    "                ]:\n",
    "    results = pd.DataFrame()\n",
    "    path= \"..\"\n",
    "    if category in [\"balanced_data\", \"imbalanced_data\"]:\n",
    "        files = glob2.glob(f'{path}/R/simulated_data/{category}/*.h5')\n",
    "        files = [f[len(f\"{path}/R/simulated_data/{category}/\"):-3] for f in files]\n",
    "\n",
    "    else:\n",
    "        files = glob2.glob(f'{path}/real_data/*.h5')\n",
    "        files = [f[len(f\"{path}/real_data/\"):-3] for f in files]\n",
    "        results = pd.read_pickle(\n",
    "                        f\"../output/pickle_results/{category}/{category}_graph_creation.pkl\")\n",
    "        files = files[1:]\n",
    "    print(files)\n",
    "    \n",
    "    for dataset in files:\n",
    "        if category in [\"balanced_data\", \"imbalanced_data\"]:\n",
    "            data_mat = h5py.File(f\"{path}/R/simulated_data/{category}/{dataset}.h5\",\"r\")\n",
    "        else:\n",
    "            data_mat = h5py.File(f\"{path}/real_data/{dataset}.h5\",\"r\")\n",
    "        print(f\">> {dataset}\")\n",
    "\n",
    "        Y = np.array(data_mat['Y'])\n",
    "        X = np.array(data_mat['X'])\n",
    "\n",
    "        genes_idx, cells_idx = train.filter_data(X, highly_genes=nb_genes)\n",
    "        X = X[cells_idx][:, genes_idx]\n",
    "        Y = Y[cells_idx]\n",
    "        n_clusters = len(np.unique(Y))\n",
    "\n",
    "        for normalize_weights in [\"log_per_cell\", \"per_cell\", \"none\"]:\n",
    "            for node_features in [\"scale\", \"none\", \"scale_by_cell\"]:\n",
    "                for edge_norm in [True, False]:\n",
    "\n",
    "                    graph = train.make_graph(\n",
    "                        X,\n",
    "                        Y,\n",
    "                        dense_dim=pca_size,\n",
    "                        node_features=node_features,\n",
    "                        normalize_weights=normalize_weights,\n",
    "                        edge_norm =edge_norm\n",
    "                    )\n",
    "\n",
    "                    labels = graph.ndata[\"label\"]\n",
    "                    train_ids = np.where(labels != -1)[0]\n",
    "\n",
    "                    sampler = dgl.dataloading.MultiLayerFullNeighborSampler(n_layers)\n",
    "\n",
    "                    dataloader = dgl.dataloading.NodeDataLoader(\n",
    "                        graph,\n",
    "                        train_ids,\n",
    "                        sampler,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True,\n",
    "                        drop_last=False,\n",
    "                        num_workers=1,\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"INPUT: {model_name}  {hidden_dim}, {hidden}, {same_edge_values}, {edge_norm}\"\n",
    "                    )\n",
    "                    t1 = time.time()\n",
    "\n",
    "                    for run in range(3):\n",
    "                        t_start = time.time()\n",
    "                        torch.manual_seed(run)\n",
    "                        torch.cuda.manual_seed_all(run)\n",
    "                        np.random.seed(run)\n",
    "                        random.seed(run)\n",
    "\n",
    "                        model = models.GCNAE(\n",
    "                            in_feats=pca_size,\n",
    "                            n_hidden=hidden_dim,\n",
    "                            n_layers=n_layers,\n",
    "                            activation=activation,\n",
    "                            dropout=0.1,\n",
    "                            hidden=hidden,\n",
    "                            hidden_relu=hidden_relu,\n",
    "                            hidden_bn=hidden_bn,\n",
    "                        ).to(device)\n",
    "                        if run == 0:\n",
    "                            print(f\">\", model)\n",
    "\n",
    "                        optim = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "                        scores = train.train(model, optim, epochs, dataloader, n_clusters,  plot=False,\n",
    "                                            cluster=[\"KMeans\", \"Leiden\"])\n",
    "                        scores[\"dataset\"] = dataset\n",
    "                        scores[\"run\"] = run\n",
    "                        scores[\"nb_genes\"] = nb_genes\n",
    "                        scores[\"node_features\"] = node_features\n",
    "                        scores[\"normalize_weights\"] = normalize_weights\n",
    "                        scores[\"edge_norm\"] = edge_norm\n",
    "\n",
    "                        results = results.append(scores, ignore_index = True)\n",
    "\n",
    "                        results.to_pickle(\n",
    "                            f\"../output/pickle_results/{category}/{category}_graph_creation.pkl\")\n",
    "                        print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = {\"log_per_cell\": 2,\n",
    "        \"none\": 0,\n",
    "        \"per_cell\":1}\n",
    "for category in [\"real_data\", \"balanced_data\", \"imbalanced_data\"]:\n",
    "    print(category)\n",
    "    results = pd.read_pickle(\n",
    "        f\"../output/pickle_results/{category}/{category}_graph_creation.pkl\")\n",
    "    results = results.sort_values(by=\"edge_norm\", ascending = False).groupby([ \n",
    "        \"edge_norm\", \"node_features\",\"normalize_weights\",\n",
    "                     ])[[\"kmeans_ari\"]].mean().round(2).reset_index()\n",
    "    results[\"order\"] = results[\"normalize_weights\"].apply(lambda x: order[x])\n",
    "    display(results.sort_values(by= [\"edge_norm\", \"node_features\" ,\"order\",],\n",
    "                               ascending = [False, True, True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
